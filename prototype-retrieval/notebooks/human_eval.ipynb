{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b459e1ccd854e432e4dd220178642c3c94442aa125d1d3c88814638f54b7d686"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sacremoses import MosesDetokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "md = MosesDetokenizer(lang='en')\n",
    "type_map = {\n",
    "    \"name\": \"Name\",\n",
    "    \"eatType\": \"Eat type\",\n",
    "    \"food\": \"Food\",\n",
    "    \"customerRating\": \"Customer rating\",\n",
    "    \"area\": \"Area\",\n",
    "    \"familyFriendly\": \"Family friendly\",\n",
    "    \"priceRange\": \"Price range\",\n",
    "    \"near\": \"Near\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(fname, strip=True):\n",
    "    with open(fname, \"r\") as f:\n",
    "        if strip:\n",
    "            return [line.strip() for line in f]\n",
    "        else:\n",
    "            return [line for line in f]\n",
    "\n",
    "def postprocess_e2e_preds(preds):\n",
    "    processed_preds = []\n",
    "    for pred in tqdm(preds):\n",
    "        processed_preds.append(md.detokenize(pred.replace(\"_\", \" \").split()))\n",
    "    return processed_preds\n",
    "\n",
    "def process_type_lines(type_lines):\n",
    "    processed_types = []\n",
    "    for type_line in type_lines:\n",
    "        processed_types.append([type_map[type] for type in type_line.split()])\n",
    "    return processed_types\n",
    "\n",
    "def process_value(value):\n",
    "        if value == \"family_friendly\":\n",
    "            return \"yes\"\n",
    "        elif value == \"not_family_friendly\":\n",
    "            return \"no\"\n",
    "        else:\n",
    "            return value.replace(\"_\", \" \")\n",
    "\n",
    "def process_value_lines(value_lines):\n",
    "    processed_values = []\n",
    "    for value_line in value_lines:\n",
    "        processed_values.append([process_value(value) for value in value_line.split()])\n",
    "    return processed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/projects/ogma2/users/andrewsi/control-data2text/DTG-SI/e2e_data/val\"\n",
    "baseline_preds_file = \"/projects/ogma2/users/andrewsi/control-data2text/transformers/examples/seq2seq/exp/e2e/e2e_t5_small_01/checkpoint-10000/validation_preds.txt\"\n",
    "dtg_si_preds_file = \"/projects/ogma2/users/andrewsi/control-data2text/DTG-SI/e2e_dtg_si/ckpt/hypos.step1200.val.txt\"\n",
    "our_preds_file = \"/projects/ogma2/users/andrewsi/control-data2text/transformers/examples/seq2seq/exp/e2e/e2e_k3_t5_small_01/checkpoint-8295/validation_preds.txt\"\n",
    "\n",
    "x_types = process_type_lines(read_from_file(f\"{data_dir}/x_type.valid.txt\"))\n",
    "x_values = process_value_lines(read_from_file(f\"{data_dir}/x_value.valid.txt\"))\n",
    "y_refs = postprocess_e2e_preds(read_from_file(f\"{data_dir}/y_ref.valid.txt\"))\n",
    "\n",
    "baseline_preds = postprocess_e2e_preds(read_from_file(baseline_preds_file))\n",
    "dtg_si_preds = postprocess_e2e_preds(read_from_file(dtg_si_preds_file))\n",
    "our_preds = postprocess_e2e_preds(read_from_file(our_preds_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sheet = []\n",
    "eval_sample = np.random.choice(len(x_type_lines), 100, replace=False)\n",
    "for i in eval_sample:\n",
    "    eval_sheet.append([\"Table\", \"\", \"Exemplar\", \"Generations\", \"Factual Consistency\", \"Style Embodiment\", \"Fluency\", \"ID\", str(i)])\n",
    "    gens = [baseline_preds[i], dtg_si_preds[i], our_preds[i]]\n",
    "    gen_idx_perm = np.random.permutation(range(3))\n",
    "    shuffled_gens = [gens[i] for i in gen_idx_perm]\n",
    "    eval_sheet.append([x_types[i][0], x_values[i][0], y_refs[i], shuffled_gens[0], \"\", \"\", \"\", str(gen_idx_perm[0]), \"\"])\n",
    "    eval_sheet.append([x_types[i][1], x_values[i][1], \"\", shuffled_gens[1], \"\", \"\", \"\", str(gen_idx_perm[1]), \"\"])\n",
    "    eval_sheet.append([x_types[i][2], x_values[i][2], \"\", shuffled_gens[2], \"\", \"\", \"\", str(gen_idx_perm[2]), \"\"])\n",
    "    for j in range(3, len(x_types[i])):\n",
    "        eval_sheet.append([x_types[i][j], x_values[i][j], \"\", \"\", \"\", \"\", \"\", \"\", \"\"])\n",
    "    eval_sheet.append([\"\"] * 9)\n",
    "    eval_sheet.append([\"\"] * 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(eval_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(\"e2e_human_eval.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}