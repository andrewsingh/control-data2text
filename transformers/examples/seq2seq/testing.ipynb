{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('sr-env': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "b459e1ccd854e432e4dd220178642c3c94442aa125d1d3c88814638f54b7d686"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    T5Tokenizer\n",
    ")\n",
    "from sacremoses import MosesDetokenizer\n",
    "\n",
    "ROOT_DIR = \"/projects/ogma2/users/andrewsi/control-data2text\"\n",
    "gpu = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "totto_dir = f\"{ROOT_DIR}/google-language/language/totto\"\n",
    "temp_dir = f\"{totto_dir}/temp\"\n",
    "parent_preds_file = f\"{temp_dir}/t5_small_64158.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = subprocess.run([\"bash\", totto_dir + \"/totto_parent_eval.sh\", \"--prediction_path\", parent_preds_file, \"--target_path\", totto_dir + \"/totto_data/totto_dev_data.jsonl\", \"--output_dir\", temp_dir], stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_metric(results, metric):\n",
    "            return float(re.search(\"{} = ([0-9]+.[0-9]+)\".format(metric), results).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "b'Running with the following variables:\\nPREDICTION_PATH   : /projects/ogma2/users/andrewsi/control-data2text/google-language/language/totto/temp/preds_k10_126000.txt\\nTARGET_PATH       : /projects/ogma2/users/andrewsi/control-data2text/google-language/language/totto/totto_data/totto_dev_data.jsonl \\nBLEURT_CKPT       : unset \\nOUTPUT_DIR        : /projects/ogma2/users/andrewsi/control-data2text/google-language/language/totto/temp\\nMODE              : dev\\nWriting references.\\nWriting tables in PARENT format.\\nPreparing predictions.\\nWriting predictions.\\nRunning detokenizers.\\n======== EVALUATE OVERALL ========\\nComputing PARENT (overall)\\nEvaluated 7700 examples.\\nPrecision = 65.53 Recall = 44.58 F-score = 47.29\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "results.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_metrics = [\"Precision\", \"Recall\", \"F-score\"]\n",
    "metric_dict = {}\n",
    "for metric in parent_metrics:\n",
    "    metric_dict[metric] = get_parent_metric(str(results.stdout), metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Precision': 65.53, 'Recall': 44.58, 'F-score': 47.29}"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_model_path = f\"{ROOT_DIR}/transformers/examples/language-modeling/exp/e2e_targets/gpt2-02/checkpoint-9464\"\n",
    "totto_model_path = f\"{ROOT_DIR}/transformers/examples/language-modeling/exp/totto_targets/gpt2/checkpoint-20264\"\n",
    "\n",
    "def compute_perplexity(preds, tokenizer, language_model, device):\n",
    "    language_model.to(device)\n",
    "    ppls = []\n",
    "    print(f\"First pred: {preds[0]}\")\n",
    "    for pred in tqdm(preds):\n",
    "        inputs = tokenizer(pred, return_tensors='pt').to(device)\n",
    "        outputs = language_model(**inputs, labels=inputs['input_ids'])\n",
    "        ppls.append(math.exp(outputs.loss))\n",
    "    return round((sum(ppls) / len(ppls)), 4)\n",
    "\n",
    "def compute_e2e_ppl(preds):\n",
    "    device = f\"cuda:{gpu}\"\n",
    "    e2e_lm_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    e2e_lm = GPT2LMHeadModel.from_pretrained(e2e_model_path)\n",
    "    return compute_perplexity(preds, e2e_lm_tokenizer, e2e_lm, device)\n",
    "\n",
    "def compute_totto_ppl(preds):\n",
    "    device = f\"cuda:{gpu}\"\n",
    "    totto_lm_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    totto_lm = GPT2LMHeadModel.from_pretrained(totto_model_path)\n",
    "    return compute_perplexity(preds, totto_lm_tokenizer, totto_lm, device)\n",
    "\n",
    "def process_and_get_e2e_ppl(inpath):\n",
    "    return compute_e2e_ppl(postprocess_e2e_preds(inpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MosesDetokenizer(lang='en')\n",
    "\n",
    "def postprocess_e2e_preds(inpath, outpath=None):\n",
    "    processed_lines = []\n",
    "    with open(inpath, \"r\") as f:\n",
    "        original_lines = [line for line in f]\n",
    "    for line in tqdm(original_lines):\n",
    "        processed_lines.append(md.detokenize(line.strip().replace(\"_\", \" \").split()))\n",
    "    if outpath:\n",
    "        with open(outpath, \"w+\") as f:\n",
    "            f.writelines([line + \"\\n\" for line in processed_lines])\n",
    "    return processed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 6300/6300 [00:02<00:00, 2247.01it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = postprocess_e2e_preds(\"/projects/ogma2/users/andrewsi/control-data2text/transformers/examples/seq2seq/exp/e2e/e2e_k3_t5_small_01/checkpoint-8295/validation_preds.txt\", \"/projects/ogma2/users/andrewsi/control-data2text/transformers/examples/seq2seq/exp/e2e/e2e_k3_t5_small_01/checkpoint-8295/validation_preds_postprocessed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"/projects/ogma2/users/andrewsi/control-data2text/DTG-SI/e2e_data/train/y_aux.train.txt\"\n",
    "val_file = \"/projects/ogma2/users/andrewsi/control-data2text/DTG-SI/e2e_data/val/y_aux.valid.txt\"\n",
    "test_file = \"/projects/ogma2/users/andrewsi/control-data2text/DTG-SI/e2e_data/test/y_aux.test.txt\"\n",
    "outdir = \"/projects/ogma2/users/andrewsi/control-data2text/transformers/examples/language-modeling/test_data/e2e_targets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 6274/6274 [00:04<00:00, 1565.00it/s]\n"
     ]
    }
   ],
   "source": [
    "postprocess_e2e_preds(test_file, f\"{outdir}/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 6300/6300 [00:03<00:00, 1916.88it/s]\n",
      "  0%|          | 5/6300 [00:00<02:13, 47.23it/s]First pred: Loch Fyne near The Rice Boat has a high customer rating. It serves French food in riverside.\n",
      "100%|██████████| 6300/6300 [01:52<00:00, 56.10it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.9865"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "process_and_get_e2e_ppl(\"/projects/ogma2/users/andrewsi/control-data2text/transformers/examples/seq2seq/exp/e2e/e2e_k5_t5_small_01/checkpoint-18432/validation_preds.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_longer(col, thresh):\n",
    "    return len(col[col > thresh]) / len(col)\n",
    "\n",
    "def get_len_df(data_file):\n",
    "    with open(data_file, \"r\") as f:\n",
    "        data_lines = [line for line in f]\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", model_max_length=4096)\n",
    "    special_tokens = [\"[SEP]\"]\n",
    "        \n",
    "    if len(special_tokens) > 0:\n",
    "        special_tokens_dict = {\"additional_special_tokens\": (special_tokens)}\n",
    "        tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    print(\"\\nTokenizer length: {}\".format(len(tokenizer)))\n",
    "    \n",
    "    src_lens = []\n",
    "    tgt_lens = []\n",
    "    print(f\"Num lines: {len(data_lines)}\\nFirst line: {data_lines[0]}\")\n",
    "    for line in tqdm(data_lines):\n",
    "        json_example = json.loads(line)\n",
    "        src_lens.append(len(tokenizer(json_example[\"source\"], max_length=4096, truncation=True)['input_ids'])) \n",
    "        tgt_lens.append(len(tokenizer(json_example[\"target\"], max_length=4096, truncation=True)['input_ids']))\n",
    "\n",
    "    return pd.DataFrame([src_lens, tgt_lens], index=[\"src_len\", \"tgt_len\"]).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "totto_gtt = \"/projects/ogma2/users/andrewsi/control-data2text/transformers/examples/language-modeling/test_data/totto_targets/validation.txt\"\n",
    "totto_baseline = \"/projects/ogma2/users/andrewsi/controllable-data-to-text/examples/seq2seq/results/totto/baseline/t5-small/checkpoint-67932/test_generations.txt\"\n",
    "totto_val_clean_source_embed = \"/projects/ogma2/users/andrewsi/control-data2text/transformers/examples/seq2seq/exp/totto/totto_k5_t5_small_new_parent/eval_results/val_clean_source_embed/preds.txt\"\n",
    "preds_file = \"/projects/ogma2/users/andrewsi/control-data2text/transformers/examples/seq2seq/exp/totto/totto_k5_t5_masked_target_embed_new_parent/eval_results/val_clean_source_embed/preds.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 6/7700 [00:00<02:16, 56.16it/s]First pred: Daniel Henry Chamberlain was the 76th Governor of South Carolina on December 1, 1874.\n",
      "100%|██████████| 7700/7700 [02:23<00:00, 53.71it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "64.8"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "with open(preds_file, \"r\") as f:\n",
    "    preds = [pred.strip() for pred in f]\n",
    "compute_totto_ppl(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_perplexity(totto_baseline)"
   ]
  }
 ]
}